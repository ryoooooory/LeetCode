# 学んだこと

### L1 キャッシュ

https://github.com/hroc135/leetcode/pull/24/files で、L1 キャッシュでの速度について議論があったので自分でも概念などを調査した。
oda さん推奨の本など（ブログに記載あったもの）で目に触れていたが、実際にその知識を利用して何かしらに役立てていたことがなかったのでとても良い機会になった（再度本も読み直したい）

CPU 内部の最も高速なメモリ。CPU 内部に統合されていてコアごとに搭載されているらしい。→ レジスターをメモリとして捉えるとそちらのが高速なので最もというのはいいすぎかも
レイテンシが非常に小さくメインメモリよりも高速。
メインメモリへのアクセスに比べて早いので、キャッシュヒットすれば高速でデータ取得 → 処理の継続が可能。
各キャッシュの比較についてはしたの通り。
| キャッシュ | 容量 | アクセス速度 |
| ---- | ---- | ---- |
| L1 | 32~128KB | 最速 |
| L2 | 256KB~2MB | L1 以下|
| L3 | 2MB~64MB | L2 以下だが RAM（メインメモリ）より高速 |

### キャッシュに格納するデータの大きさ

格納する単位データをキャッシュライン（またはブロック）、大きさをキャッシュラインサイズ（またはラインサイズ）と呼ぶ。
基本的にラインサイズが大きい方がメモリとの転送が減るので効率的だが、キャッシュとして使われない部分も増えたり、ライン数がへりキャッシュミスの可能性が増えるデメリットもある。逆にラインサイズをキャッシュヒット率では優れるが、メモリからの転送回数がふえたり管理のオーバーヘッドが増えるといったデメリットがある。

### キャッシュ方式　

ラインサイズとライン数がきまると、どのラインにどのように情報を格納するかを考える。
読み出されるアドレスについて、キャッシュ内の対応ラインを Index,　ライン内でのアドレスをライン内アドレス（ブロック内アドレス）、その他のアドレス部分をタグ（key）と呼ぶ。またタグを管理するための Array をタグメモリ（キャッシュディレクトリ）と呼ぶ。タグメモリには Index の位置にそのアドレスのタグを入れていく。タグメモリの深さはライン数分となる。
つまりタグメモリはアドレスが指定するものがキャッシュにあるかを高速で判定するために、キャッシュ内の Index に入っているデータをタグで判定するもの

### Direct Mapped

基本的に CPU からアドレスが来た時、アドレスの Index を使ってタグメモリに入っているデータを参照し、そこにそのアドレスのタグが入っていればキャッシュがヒットしたことになり、実際にキャッシュを Index を元に取得できる（実際はこれは判定と取得を同時に行なっているらしい）
ヒットしなかった時は、主記憶から読み出されキャッシュにコピーされる。これをリプレイスと呼び、そのあとタグメモリも更新される。
ブロックがたくさんある時に、Index が被ると共存できない（どっちのブロックか判定できないか）、これを競合ミス呼ぶ

### N-way set associative

上記であった、競合ミスを減らすために index の数を半分にしてブロックを１つのセットとして考える。こうなると、セットの中でそれぞれのブロックを Way とし、１セットに 2way あることになる。これに伴い、タグメモリもセット分だけ用意する。
こうすると、CPU からアドレスが来た時に way 分のタグメモリを並列で確認し、片方でも一致すればヒットとなる。このように way を増やすことで競合ミスの可能性を減らすことができる。ただ並列処理ではあるが比較コストなどが少しかかる。
上記を 2-way set associative とよび、way の数に合わせて n-way となる。
実際、全アドレスが同確率でアクセスされることを考えると、Index の数は半分になっているので競合ミスの確率は変わらない。ただ、アクセスは局在性があるので、特定のアドレスに偏ることがほとんどであるので、基本的に way が多いと競合ミスは減る。だいたい Direct の２倍くらいの性能になるらしい。

### Fully Associative

Index をなくし、Way をめちゃ増やしてセットを１つにするのをフルマップ（Fully Associative）と呼ぶ。
Index がないので、キャッシュのどのブロックにデータを格納することが可能。
Index がないので、タグメモリ全体を検索することになるので効率は悪い。

### False sharing

マルチスレッドで発生するキャッシュの奪い合いにより性能が落ちる現象。
複数の変数が物理的に近いメモリアドレスにあると、同じキャッシュラインにのり、その結果複数で違う変数をいじってもキャッシュラインが同じことによって、キャッシュライン全体がメモリへの書き戻しやスレッドのブロックなどが発生し頻繁に同期処理が走り性能が落ちるというもの。

### 参考資料

慶應の授業資料？がとても良かった。推奨図書のものはまだみてないが、メモリ関連をざっとみる時にとてもよさそう（情報系の学部はこれを授業でできていいなあという気持ちになった泣）
https://www.am.ics.keio.ac.jp/parthenon/cache.pdf
